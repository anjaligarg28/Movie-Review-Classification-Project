{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30474,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis: Movie Review Classification\nSentiment analysis is a powerful tool that allows computers to understand the underlying subjective tone of a piece of writing. \n\nSentiment analysis is used to analyze raw text to drive objective quantitative results using natural language processing, machine learning, and other data analytics techniques. It is used to detect positive or negative sentiment in text, and often businesses use it to gauge branded reputation among their customers. \n\nThere are various types of sentiment analysis where the models focus on feelings and emotions, urgency, even intentions, and polarity. The most popular types of sentiment analysis are:\n\n1. Fine-grained sentiment analysis\n2. Emotion detection\n3. Aspect based sentiment analysis\n4. Multilingual sentiment analysis\n\nSentiment analysis is critical because it helps businesses to understand the emotion and sentiments of their customers. \n","metadata":{"id":"8ytjdil03JQ8"}},{"cell_type":"markdown","source":"# Benefits of sentiment analysis\n1. **Sorting Data at Scale**: With sentiment analysis, companies don't have to sort through customer support conversations manually, thousands of tweets, and surveys. Sentiment analysis helps businesses process vast amounts of data efficiently.\n2. **Real-Time Analysis**: It helps to identify critical issues in real-time. For example, is a crisis on social media escalating? Is there an angry customer about to churn? With Sentiment analysis models, businesses can immediately identify customer pain points and take action right away.\n3. **Consistent criteria**: A centralized sentiment analysis system can improve accuracy and deliver better insights since tagging text by sentiment is highly subjective, influenced by personal experiences, thoughts, and beliefs. ","metadata":{"id":"Q9PHW8KNsD5K"}},{"cell_type":"markdown","source":"# Project Description\n\nIMDB is an entertainment review website where people leave their **opinions on various movies and TV series**. We can perform sentiment analysis on the reviews to find whether the viewers liked/disliked the show.\n\nA movie review generally consists of some common words (articles, prepositions, pronouns, conjunctions, etc.) in any language. **These repetitive words are called stopwords that do not add much information to text. NLP libraries like spaCY and other methods like vectorizing the data efficiently remove stopwords** from review during text processing. This reduces the size of the dataset and improves multi-class model performance because the data would only contain meaningful words.\n\n**These results are useful for production companies to understand why their title succeeded or failed.**\n","metadata":{"id":"D-YZrhdAmUPl"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"id":"A7skSh1jcGtV","outputId":"9c4d7069-caf7-4ed4-e04e-482706d838e0","execution":{"iopub.status.busy":"2023-11-25T14:45:45.470827Z","iopub.execute_input":"2023-11-25T14:45:45.471274Z","iopub.status.idle":"2023-11-25T14:45:45.505605Z","shell.execute_reply.started":"2023-11-25T14:45:45.471241Z","shell.execute_reply":"2023-11-25T14:45:45.504530Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Description\nIn this project, we’ll use an IMDB dataset of 50k movie reviews available on Kaggle. The dataset contains 2 columns (review and sentiment) that will help us identify whether a review is positive or negative.\n\nDataset link: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n\nOur goal is to find which machine learning model is best suited to predict sentiment (output) given a movie review (input).","metadata":{"id":"cgslNYzaru6y"}},{"cell_type":"code","source":"file = '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv'\ndf_review = pd.read_csv(file)\nprint(df_review)","metadata":{"id":"QTcVNRdcfrAb","outputId":"6fd5746d-85ae-433c-8da7-60bfdb738209","execution":{"iopub.status.busy":"2023-11-25T14:45:45.509597Z","iopub.execute_input":"2023-11-25T14:45:45.510056Z","iopub.status.idle":"2023-11-25T14:45:47.284696Z","shell.execute_reply.started":"2023-11-25T14:45:45.510017Z","shell.execute_reply":"2023-11-25T14:45:47.283850Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"                                                  review sentiment\n0      One of the other reviewers has mentioned that ...  positive\n1      A wonderful little production. <br /><br />The...  positive\n2      I thought this was a wonderful way to spend ti...  positive\n3      Basically there's a family where a little boy ...  negative\n4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n...                                                  ...       ...\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative\n\n[50000 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Creating two seperate datasets for positive and negative reviews\n\nIMDB Dataset contains 50,000 rows\n25000 rows containts positive reviews\n25000 rows containt negative reviews\n\nWe are generating seperate datasets for positive and negative reviews to get a smaller dataset containing equal no. of each type of reviews which is going to help us to train our model faster.","metadata":{"id":"iTN-aaCNwo1H"}},{"cell_type":"code","source":"df_positive = df_review[df_review['sentiment']=='positive']\nprint(df_positive.head())\n\ndf_negative = df_review[df_review['sentiment']=='negative']\nprint(df_negative.head())","metadata":{"id":"Lbk3KWq4jPwq","outputId":"8b448090-860d-4fca-a880-09f65f2d9fc2","execution":{"iopub.status.busy":"2023-11-25T14:45:47.286666Z","iopub.execute_input":"2023-11-25T14:45:47.287295Z","iopub.status.idle":"2023-11-25T14:45:47.324762Z","shell.execute_reply.started":"2023-11-25T14:45:47.287261Z","shell.execute_reply":"2023-11-25T14:45:47.323618Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n5  Probably my all-time favorite movie, a story o...  positive\n                                               review sentiment\n3   Basically there's a family where a little boy ...  negative\n7   This show was an amazing, fresh & innovative i...  negative\n8   Encouraged by the positive comments about this...  negative\n10  Phil the Alien is one of those quirky films wh...  negative\n11  I saw this movie when I was about 12 when it c...  negative\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Random sampling to generate smaller dataset\n\nThis dataset contains 50000 rows; however, to train our model faster in the following steps, we’re going to take a smaller sample of 20000 rows. \n\nOur new dataset will containt 10,000 positive reviews and 10,000 negative reviews.\n\n***dataset_name.sample(n = no_of_rows)***\n\nThis will help us to generate 10,000 random rows from each dataset we created above.","metadata":{"id":"zb-JQhibwwn7"}},{"cell_type":"code","source":"pos_review = df_positive.sample(n = 10000)\nneg_review = df_negative.sample(n = 10000)\n\ndf_review_bal = pd.concat([pos_review, neg_review])\nprint(df_review_bal)","metadata":{"id":"SWCJTyuFjezd","outputId":"c66d8acc-af79-44b5-eacf-d1e7d3f920d3","execution":{"iopub.status.busy":"2023-11-25T14:45:47.326415Z","iopub.execute_input":"2023-11-25T14:45:47.326803Z","iopub.status.idle":"2023-11-25T14:45:47.343608Z","shell.execute_reply.started":"2023-11-25T14:45:47.326766Z","shell.execute_reply":"2023-11-25T14:45:47.342362Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"                                                  review sentiment\n44636  I just watched Holly along with another movie ...  positive\n29995  New York, I Love You finally makes it to our s...  positive\n6528   This film is a knockout, Fires on the plain re...  positive\n39038  If you enjoy romantic comedies then you will f...  positive\n65     DON'T TORTURE A DUCKLING is one of Fulci's ear...  positive\n...                                                  ...       ...\n39805  Am I wrong,or is the 2007 version just a rip-o...  negative\n48295  What I found so curious about this film--I saw...  negative\n5363   It is apparent that director, writers and ever...  negative\n47090  I have seen three other movies that are worse ...  negative\n31545  I saw this film opening weekend in Australia, ...  negative\n\n[20000 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Splitting dataset into training and test set\n\nBefore we work with our data, we need to split it into a train and test set. The train dataset will be used to fit the model, while the test dataset will be used to provide an unbiased evaluation of a final model fit on the training dataset.\n\nWe’ll use ***sklearn’s train_test_split*** to do the job. In this case, we set 33% to the test data.","metadata":{"id":"eXErFvHFw5Ov"}},{"cell_type":"code","source":"#splitting dataset into training and test set\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df_review_bal, test_size=0.33, random_state = 1)\n\ntrain_x, train_y = train['review'], train['sentiment']\ntest_x, test_y = test['review'], test['sentiment']","metadata":{"id":"MsQICfa6jrng","execution":{"iopub.status.busy":"2023-11-25T14:45:47.346746Z","iopub.execute_input":"2023-11-25T14:45:47.347204Z","iopub.status.idle":"2023-11-25T14:45:48.815980Z","shell.execute_reply.started":"2023-11-25T14:45:47.347166Z","shell.execute_reply":"2023-11-25T14:45:48.814179Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Natural language processing pipeline:\n1.\tTokenizing sentences to break text down into sentences, words, or other units.\n2.\tRemoving stop words like “if,” “but,” “or,” and so on.\n3.\tNormalizing words by condensing all forms of a word into a single form.\n4.\tVectorizing text by turning the text into a numerical representation for consumption by your classifier.","metadata":{"id":"zDPUtgPIpHtx"}},{"cell_type":"markdown","source":"# TF-IDF Vectorizer\nTerm frequency-inverse document frequency is a text vectorizer that **transforms the text into a usable vector.**\n\nThe term frequency is the number of occurrences of a specific term in a document.\nDocument frequency is the number of documents containing a specific term. \n\nInverse document frequency (IDF) is the weight of a term, it aims to reduce the weight of a term if the term’s occurrences are scattered throughout all the documents.\n\nWhen the number of DF is equal to n which means that the term appears in all documents, the IDF will be zero, when in doubt just put this term in the stopword list because it doesn't provide much information.\n\nThe TF-IDF score as the name suggests is just a multiplication of the term frequency matrix with its IDF.\n\n","metadata":{"id":"ktNttUt7qfay"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(stop_words='english')\ntrain_x_vector = tfidf.fit_transform(train_x)\n#print(train_x_vector)\n\npd.DataFrame.sparse.from_spmatrix(train_x_vector,\n                                  index=train_x.index,\n                                  columns=tfidf.get_feature_names_out())\n\ntest_x_vector = tfidf.transform(test_x)\n#print(test_x_vector)","metadata":{"id":"801Tf9pvj0s3","execution":{"iopub.status.busy":"2023-11-25T14:45:48.818002Z","iopub.execute_input":"2023-11-25T14:45:48.818400Z","iopub.status.idle":"2023-11-25T14:45:56.058629Z","shell.execute_reply.started":"2023-11-25T14:45:48.818366Z","shell.execute_reply":"2023-11-25T14:45:56.057532Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Training and Classification using Support Vector Machine (SVM)\n\nThe goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane.","metadata":{"id":"kIOaLOsVxAz1"}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(kernel= 'linear')\nsvc.fit(train_x_vector, train_y)\n\nprint(svc.predict(tfidf.transform(['A good movie'])))\nprint(svc.predict(tfidf.transform(['An excellent movie'])))\nprint(svc.predict(tfidf.transform(['I did not like this movie at all'])))","metadata":{"id":"-fgPM9rWj84T","outputId":"7dd11b7f-a9c4-4530-e419-766b5e2ffe02","execution":{"iopub.status.busy":"2023-11-25T14:45:56.060024Z","iopub.execute_input":"2023-11-25T14:45:56.060454Z","iopub.status.idle":"2023-11-25T14:48:14.854073Z","shell.execute_reply.started":"2023-11-25T14:45:56.060416Z","shell.execute_reply":"2023-11-25T14:48:14.852497Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['positive']\n['positive']\n['negative']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training and Classification using Decision Tree Classifer\nThe intuition behind Decision Trees is that you use the dataset features to create yes/no questions and continually split the dataset until you isolate all data points belonging to each class.\n\nWith this process you’re organizing the data in a tree structure.\n\nEvery time you ask a question you’re adding a node to the tree. And the first node is called the root node.\n\nThe result of asking a question splits the dataset based on the value of a feature, and creates new nodes.\n\nIf you decide to stop the process after a split, the last nodes created are called leaf nodes.","metadata":{"id":"RukFHYWDxN7Q"}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndec_tree = DecisionTreeClassifier()\ndec_tree.fit(train_x_vector, train_y)\n\nprint(dec_tree.predict(tfidf.transform(['A good movie'])))\nprint(dec_tree.predict(tfidf.transform(['An excellent movie'])))\nprint(dec_tree.predict(tfidf.transform(['I did not like this movie at all'])))","metadata":{"id":"ykWc3ys8kUkQ","outputId":"6873eb01-c1fc-4e8e-b586-47979a23ccc8","execution":{"iopub.status.busy":"2023-11-25T14:48:14.856487Z","iopub.execute_input":"2023-11-25T14:48:14.856986Z","iopub.status.idle":"2023-11-25T14:48:32.150929Z","shell.execute_reply.started":"2023-11-25T14:48:14.856940Z","shell.execute_reply":"2023-11-25T14:48:32.149688Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"['positive']\n['positive']\n['positive']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training and Classification using Gaussian Naive Bayes Classifier\n\nNaïve Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.\nIt is mainly used in text classification that includes a high-dimensional training dataset.\nIt is a probabilistic classifier, which means it predicts on the basis of the probability of an object.","metadata":{"id":"iGoxdKmdxSYH"}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(train_x_vector.toarray(), train_y)\n\nprint(gnb.predict(tfidf.transform(['A good movie']).toarray()))\nprint(gnb.predict(tfidf.transform(['An excellent movie']).toarray()))\nprint(gnb.predict(tfidf.transform(['I did not like this movie at all']).toarray()))","metadata":{"id":"fPn6txQskYCe","outputId":"11733c17-ccb9-4e57-fc06-db795a83d12f","execution":{"iopub.status.busy":"2023-11-25T14:48:32.152320Z","iopub.execute_input":"2023-11-25T14:48:32.152682Z","iopub.status.idle":"2023-11-25T14:48:54.014288Z","shell.execute_reply.started":"2023-11-25T14:48:32.152645Z","shell.execute_reply":"2023-11-25T14:48:54.012948Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['negative']\n['negative']\n['negative']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training and Classification using Logistic Regression\nLogistic regression predicts the output of a categorical dependent variable. Therefore the outcome must be a categorical or discrete value. It can be either Yes or No, 0 or 1, true or False, etc. but instead of giving the exact value as 0 and 1, it gives the probabilistic values which lie between 0 and 1.\n\nIn Logistic regression, instead of fitting a regression line, we fit an \"S\" shaped logistic function, which predicts two maximum values (0 or 1).\n","metadata":{"id":"egcKH2zFxXTg"}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(train_x_vector, train_y)\n\nprint(log_reg.predict(tfidf.transform(['A good movie'])))\nprint(log_reg.predict(tfidf.transform(['An excellent movie'])))\nprint(log_reg.predict(tfidf.transform(['I did not like this movie at all'])))","metadata":{"id":"WlrN9sZdxcfm","outputId":"9ad204aa-3812-4f68-e43a-899dec717cbd","execution":{"iopub.status.busy":"2023-11-25T14:48:54.016012Z","iopub.execute_input":"2023-11-25T14:48:54.016498Z","iopub.status.idle":"2023-11-25T14:48:55.610512Z","shell.execute_reply.started":"2023-11-25T14:48:54.016457Z","shell.execute_reply":"2023-11-25T14:48:55.608972Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['positive']\n['positive']\n['negative']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Comparing models' performance\nUsing the sklearn library we can find out the scores of our ML Model and thus choose the algorithm with a higher score to predict our output.","metadata":{"id":"6ODoZlyPxud0"}},{"cell_type":"code","source":"print(svc.score(test_x_vector, test_y))\nprint(dec_tree.score(test_x_vector, test_y))\nprint(gnb.score(test_x_vector.toarray(), test_y))\nprint(log_reg.score(test_x_vector, test_y))","metadata":{"id":"9vJ7s5kFxt8d","outputId":"0fce0860-0617-430e-f542-d6198cd58499","execution":{"iopub.status.busy":"2023-11-25T14:48:55.622629Z","iopub.execute_input":"2023-11-25T14:48:55.628174Z","iopub.status.idle":"2023-11-25T14:49:49.548828Z","shell.execute_reply.started":"2023-11-25T14:48:55.628108Z","shell.execute_reply":"2023-11-25T14:49:49.547444Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"0.8834848484848485\n0.7215151515151516\n0.65\n0.8784848484848485\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# F1 score and confusion matrix for our highest performance model\nF1 score is a machine learning evaluation metric that measures a model's accuracy. It combines the precision and recall scores of a model. \n\nPrecision: Within everything that has been predicted as a positive, precision counts the percentage that is correct.\n\nRecall: Within everything that actually is positive, how many did the model succeed to find.\n\nThe F1 score is defined as the harmonic mean of precision and recall.\nF1 score has been designed to work well on imbalanced data.","metadata":{"id":"Vw-pyJjmlUGg"}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(test_y, svc.predict(test_x_vector),\n         labels=['positive', 'negative'],\n         average=None)","metadata":{"id":"QZQFi8CjljPS","outputId":"898b8db1-c100-43de-b1c4-be3c958a4828","execution":{"iopub.status.busy":"2023-11-25T14:49:49.550337Z","iopub.execute_input":"2023-11-25T14:49:49.550684Z","iopub.status.idle":"2023-11-25T14:50:32.836028Z","shell.execute_reply.started":"2023-11-25T14:49:49.550657Z","shell.execute_reply":"2023-11-25T14:50:32.835166Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([0.88582034, 0.88105182])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(test_y, \n                            svc.predict(test_x_vector),\n                            labels=['positive', 'negative']))","metadata":{"id":"TZpk4J4RlopC","outputId":"eebac350-6a1c-498d-9713-89bb225ec75b","execution":{"iopub.status.busy":"2023-11-25T14:50:32.837113Z","iopub.execute_input":"2023-11-25T14:50:32.837800Z","iopub.status.idle":"2023-11-25T14:51:16.367105Z","shell.execute_reply.started":"2023-11-25T14:50:32.837768Z","shell.execute_reply":"2023-11-25T14:51:16.365824Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    positive       0.88      0.90      0.89      3329\n    negative       0.89      0.87      0.88      3271\n\n    accuracy                           0.88      6600\n   macro avg       0.88      0.88      0.88      6600\nweighted avg       0.88      0.88      0.88      6600\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**A confusion matrix is a table that allows visualization of the performance of an algorithm. This table typically has two rows and two columns that report the number of false positives, false negatives, true positives, and true negatives**\n\nArray represents: \n\nTP, FP\n\nFN, TN","metadata":{"id":"02pzm54a493E"}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(test_y, \n                            svc.predict(test_x_vector), \n                            labels=['positive', 'negative']))","metadata":{"id":"FoWLOx2gls0E","outputId":"0081fe69-9dd7-48cd-d2c3-5a22ef994827","execution":{"iopub.status.busy":"2023-11-25T14:51:16.368734Z","iopub.execute_input":"2023-11-25T14:51:16.369100Z","iopub.status.idle":"2023-11-25T14:51:59.301346Z","shell.execute_reply.started":"2023-11-25T14:51:16.369069Z","shell.execute_reply":"2023-11-25T14:51:59.300125Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[[2983  346]\n [ 423 2848]]\n","output_type":"stream"}]}]}